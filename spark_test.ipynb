{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spark-test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOx61FLw+8todqUzFn55A7m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kkushal05/tutorials/blob/main/spark_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "sudo apt install -y mongodb >log\n",
        "service mongodb start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3ElhyPq3zJ7",
        "outputId": "d0930c2a-5bee-4c66-c97a-3c819ec830f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Starting database mongodb\n",
            "   ...done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 8.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "ps -ef | grep mongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92eanyq83_92",
        "outputId": "43b061bc-4071-42cc-a8cb-0e77d2bdb6c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mongodb      485       1 68 14:04 ?        00:00:00 /usr/bin/mongod --config /etc/mongodb.conf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "client = MongoClient()\n",
        "client.list_database_names() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pOmvssI4FCE",
        "outputId": "89d52d1e-5b67-46eb-bef4-b933fe163824"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['admin', 'local']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install pyspark\n",
        "!pip install pymongo\n",
        "!pip install sodapy\n",
        "!pip install progressbar"
      ],
      "metadata": {
        "id": "FTS218TP4kK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sodapy import Socrata\n",
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "import progressbar\n",
        "from pyspark.sql import Row\n",
        "import os\n",
        "\n",
        "client = Socrata(\"data.cityofnewyork.us\", None)\n",
        "start = 0\n",
        "chunk_size = 50\n",
        "results = []\n",
        "spark = SparkSession.builder.appName('sparkdf').getOrCreate()\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"mongodbtest1\") \\\n",
        "    .master('local')\\\n",
        "    .config(\"spark.mongodb.input.uri\", \"mongodb://127.0.0.1:27017/nypd_raw_data\") \\\n",
        "    .config(\"spark.mongodb.output.uri\", \"mongodb:/127.0.0.1:27017/nypd_raw_data\") \\\n",
        "    .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.12:3.0.1') \\\n",
        "    .getOrCreate()\n",
        "\n",
        "mongo_client = MongoClient()\n",
        "db = mongo_client['raw_data']\n",
        "\n",
        "def load_data_for_nypd_call_for_service():\n",
        "  start = 0\n",
        "  chunk_size = 50\n",
        "  data_id = \"n2zq-pubd\";\n",
        "  cols = \"NYPD_PCT_CD, BORO_NM, TYP_DESC, ARRIVD_TS, ADD_TS\"\n",
        "  db.call_for_service.drop()\n",
        "  record_count = client.get(data_id, select=\"COUNT(*)\")\n",
        "\n",
        "  while True: \n",
        "    results = client.get(data_id, select=cols, offset=start, limit=chunk_size)\n",
        "    dataframe = spark.createDataFrame(results)\n",
        "    dataframe = dataframe.na.drop()\n",
        "    for item in dataframe.collect():\n",
        "      db.call_for_service.insert_one(item.asDict())\n",
        "    print(\"Record count in  DB : \" + str(db.call_for_service.count_documents({})))\n",
        "    start = start + chunk_size\n",
        "    if start > int(record_count[0]['COUNT']):\n",
        "        break\n",
        "\n",
        "def load_data_for_ems():\n",
        "  start = 0\n",
        "  chunk_size = 50\n",
        "  data_id = \"76xm-jjuj\";\n",
        "  cols = \"INCIDENT_DATETIME, BOROUGH, POLICEPRECINCT, FIRST_ON_SCENE_DATETIME\"\n",
        "  record_count = client.get(data_id, select=\"COUNT(*)\")\n",
        "  db.ems.drop()\n",
        "\n",
        "  while True: \n",
        "    results = client.get(data_id, select=cols, offset=start, limit=chunk_size)\n",
        "    dataframe = spark.createDataFrame(results)\n",
        "    dataframe = dataframe.na.drop()\n",
        "    for item in dataframe.collect():\n",
        "      db.ems.insert_one(item.asDict())\n",
        "    print(\"Record count in  DB : \" + str(db.ems.count_documents({})))\n",
        "    start = start + chunk_size\n",
        "    if start > int(record_count[0]['COUNT']):\n",
        "        break\n",
        "\n",
        "def load_data_for_fire_dept():\n",
        "  start = 0\n",
        "  chunk_size = 50\n",
        "  data_id = \"8m42-w767\";\n",
        "  cols = \"INCIDENT_DATETIME, INCIDENT_BOROUGH, POLICEPRECINCT, FIRST_ON_SCENE_DATETIME, INCIDENT_CLASSIFICATION, INCIDENT_RESPONSE_SECONDS_QY\"\n",
        "  record_count = client.get(data_id, select=\"COUNT(*)\")\n",
        "  db.fire_dept.drop()\n",
        "\n",
        "  while True: \n",
        "    results = client.get(data_id, select=cols, offset=start, limit=chunk_size)\n",
        "    dataframe = spark.createDataFrame(results)\n",
        "    dataframe = dataframe.na.drop()\n",
        "    for item in dataframe.collect():\n",
        "      db.fire_dept.insert_one(item.asDict())\n",
        "    print(\"Record count in  DB : \" + str(db.fire_dept.count_documents({})))\n",
        "    start = start + chunk_size\n",
        "    if start > int(record_count[0]['COUNT']):\n",
        "        break\n",
        "\n",
        "load_data_for_nypd_call_for_service()\n",
        "load_data_for_fire_dept()\n",
        "load_data_for_ems()\n",
        "\n",
        "#dataframe.show()"
      ],
      "metadata": {
        "id": "BW99ahSn4bx8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}